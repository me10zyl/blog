---
title: Spark 快速入门教程（三） - 搭建集群
date: 2017-05-10 15:55:01
tags: spark
categories: spark 入门系列
---

如何搭建Spark集群？

<!-- more -->

# 概念

搭建集群前需要了解 Spark 集群的一些术语：

+ Driver 驱动器，也就是程序入口，带main函数的那个程序。
+ Master 主节点，并不会参与预算，只是用作管理集群。不要和Driver混淆，Master≠Driver。节点都是指**机器**，Driver是指带main函数的**程序**。Driver可以运行在Master上，也可以运行在Worker上，还可以运行在这两者之外的远程机器上。
+ Worker 计算节点，Spark RDD运算时就是在计算节点上执行的。
+ Executor 执行器，这个是运行在 Worker 上的真正的执行程序，这是一个**进程**，是由 Worker 上的 spark 开启并管理的，也就是说在 Worker 的 spark 程序开启远程调试，由调试客户端进行调试时，并不能成功的调试 Executor 完成 Jobs 的过程。

# 搭建

在主节点 Master 上添加 Worker 很简单，在根目录 `/conf/slaves` 配置文件添加 Worker节点 ip 或 主机名（主机名可用ssh配置）即可，也可以把自己也添加进去。

```
localhost
192.168.2.230
```

启动`/sbin/start-all`，集群开始运行，报错...无法连接到目标主机。

当然，直接启动另外一台电脑上的程序肯定不会成功，要能成功连接到 Worker，需要配置 ssh ，必须让 Master 能无密码连接到 Worker 才能启动 Worker 节点的 Spark。

1. Worker `ssh-keygen -t rsa` 生成秘钥，并添加 authorized_keys, `cat id_rsa > authorized_keys`
2. 将 Worker 的秘钥发送到 Master `scp ~/.ssh/id_rsa root@master:/.ssh/` 
3. 配置 ssh_config

连接测试 ssh 到 Worker 后，`/sbin/start-all` 成功。

# 关于启动 Worker 的两个脚本

`/sbin/` 下有两个脚本 `start-slaves.sh` 和 `start-slave.sh`，他们的区别是前者启动本Master管理的所有 Worker节点（启动别人），而`start-slave.sh`需要指定一个Master，当本机作为Worker 节点并且挂了的时候，需要重新连接到Master时使用。

# 部署模式(deploy mode) Cluster 与 Client

部署模式决定了Driver是在本地运行还是在集群上运行，Client是本地运行，而Cluster是在集群上的某一个 Worker上运行，默认是Client。通过指定spark-submit的参数--deploy-mode来指定，注意，如果是cluster模式，刚好选中的Worker必须要有驱动器程序，而且工作路径 和 提交driver时所在机器的所在路径一致, 也就是说，如果你在windows上提交driver，使用 Cluster 模式， 而选中的 Worker 是 linux系统，这是肯定不能执行成功的，因为在linux执行 driver 时，使用的是windows系统的盘符。

